# üöÄ Orchestrator - Architecture Microservices sur Kubernetes

[![Kubernetes](https://img.shields.io/badge/kubernetes-v1.28.3-blue)](https://kubernetes.io/)
[![K3s](https://img.shields.io/badge/k3s-lightweight-green)](https://k3s.io/)
[![Docker](https://img.shields.io/badge/docker-required-blue)](https://www.docker.com/)
[![Vagrant](https://img.shields.io/badge/vagrant-required-purple)](https://www.vagrantup.com/)
[![Docker Hub](https://img.shields.io/badge/images-nocrarii-orange)](https://hub.docker.com/u/nocrarii)

## üìã Description du Projet

Ce projet d√©ploie une architecture compl√®te de microservices sur un cluster Kubernetes K3s, permettant d'acqu√©rir une exp√©rience pratique avec les concepts cl√©s du DevOps : orchestration de conteneurs, d√©ploiements, services, ingresses, API gateways, CI/CD et Infrastructure as Code (IaC).

## üèóÔ∏è Architecture Compl√®te du Syst√®me

![Architecture Kubernetes Compl√®te](./architecture-diagram.png)

### Vue d'Ensemble de l'Infrastructure

L'architecture illustre un d√©ploiement Kubernetes complet avec :

#### **Couche Infrastructure (Vagrant + VirtualBox)**
- **Vagrantfile** : Orchestre la cr√©ation de 2 VMs Ubuntu
- **VMs Admin** : Machines locales pour g√©rer le cluster via kubectl

#### **Cluster K3s**
- **Master Node** : Control plane K3s (192.168.56.10)
  - API Server, Scheduler, Controller Manager
  - etcd pour le stockage de configuration
- **Agent Node** : Worker node (192.168.56.11)
  - Ex√©cute les pods des applications

#### **Couche Applicative (Namespace: microservices)**
- **API Gateway** (Deployment + HPA)
  - Point d'entr√©e unique sur NodePort 30000
  - Route vers inventory et billing services
- **Inventory App** (Deployment + HPA)
  - Gestion des films avec base PostgreSQL d√©di√©e
- **Billing App** (StatefulSet)
  - Traitement ordonn√© des commandes via RabbitMQ
- **RabbitMQ** (Deployment)
  - Message broker pour communication asynchrone

#### **Couche Donn√©es**
- **Inventory Database** (StatefulSet + PVC)
- **Billing Database** (StatefulSet + PVC)
- Volumes persistants pour garantir la durabilit√© des donn√©es

#### **Couche Configuration**
- **Secrets** : Credentials s√©curis√©s (db-secrets, rabbitmq-secrets)
- **ConfigMaps** : Configuration centralis√©e (app-config)
- **Manifests** : D√©finitions YAML dans Docker Hub

### Flux de Communication

```
Client ‚Üí API Gateway (30000) ‚Üí ‚î¨‚Üí Inventory Service (8080) ‚Üí PostgreSQL (5432)
                                ‚îÇ
                                ‚îî‚Üí RabbitMQ ‚Üí Billing Service (8080) ‚Üí PostgreSQL (5432)
```

## ‚úÖ Structure R√©elle du Projet

```
.
‚îú‚îÄ‚îÄ Manifests/
‚îÇ   ‚îú‚îÄ‚îÄ secrets/                 # Secrets K8s pour les credentials
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db-secrets.yaml      # PostgreSQL users/passwords
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rabbitmq-secrets.yaml # RabbitMQ credentials
‚îÇ   ‚îú‚îÄ‚îÄ configmaps/             # Configuration centralis√©e
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app-config.yaml     # URLs et ports des services
‚îÇ   ‚îú‚îÄ‚îÄ databases/              # StatefulSets pour les BDs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inventory-db.yaml   # PostgreSQL pour inventory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ billing-db.yaml     # PostgreSQL pour billing
‚îÇ   ‚îú‚îÄ‚îÄ apps/                   # D√©ploiements des applications
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api-gateway.yaml    # Deployment + Service NodePort
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inventory-app.yaml  # Deployment + Service ClusterIP
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ billing-app.yaml    # StatefulSet + Service Headless
‚îÇ   ‚îú‚îÄ‚îÄ messaging/              # Message Broker
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rabbitmq.yaml       # RabbitMQ avec management
‚îÇ   ‚îî‚îÄ‚îÄ autoscaling/           # HPA configurations
‚îÇ       ‚îú‚îÄ‚îÄ api-gateway-hpa.yaml    # Scale 1-3, CPU 60%
‚îÇ       ‚îî‚îÄ‚îÄ inventory-app-hpa.yaml  # Scale 1-3, CPU 60%
‚îú‚îÄ‚îÄ Scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup-kubectl.sh       # Configuration kubectl
‚îÇ   ‚îú‚îÄ‚îÄ test-api.sh           # Tests automatis√©s
‚îÇ   ‚îú‚îÄ‚îÄ healthcheck.sh        # V√©rifications sant√©
‚îÇ   ‚îî‚îÄ‚îÄ install-tools.sh      # Installation des outils
‚îú‚îÄ‚îÄ Dockerfiles/
‚îÇ   ‚îú‚îÄ‚îÄ api-gateway/           # Node.js API Gateway
‚îÇ   ‚îú‚îÄ‚îÄ inventory-app/         # Node.js Inventory Service
‚îÇ   ‚îî‚îÄ‚îÄ billing-app/          # Node.js Billing Service
‚îú‚îÄ‚îÄ Vagrantfile               # Configuration K3s cluster
‚îú‚îÄ‚îÄ orchestrator.sh          # Script principal d'orchestration
‚îî‚îÄ‚îÄ README.md                # Documentation compl√®te
```

## üê≥ Images Docker Hub

**Images publi√©es sur Docker Hub (compte nocrarii) :**
- `docker.io/nocrarii/api-gateway:latest` - [Voir sur Docker Hub](https://hub.docker.com/r/nocrarii/api-gateway)
- `docker.io/nocrarii/inventory-app:latest` - [Voir sur Docker Hub](https://hub.docker.com/r/nocrarii/inventory-app)
- `docker.io/nocrarii/billing-app:latest` - [Voir sur Docker Hub](https://hub.docker.com/r/nocrarii/billing-app)
- `docker.io/nocrarii/inventory-db:latest` - [Voir sur Docker Hub](https://hub.docker.com/r/nocrarii/inventory-db)
  - Utilis√© par: `inventory-db` (StatefulSet)
- `docker.io/nocrarii/billing-db:latest` - [Voir sur Docker Hub](https://hub.docker.com/r/nocrarii/billing-db)
  - Utilis√© par: `billing-db` (StatefulSet)
- `docker.io/nocrarii/rabbitmq:latest` - [Voir sur Docker Hub](https://hub.docker.com/r/nocrarii/rabbitmq)
  - Utilis√© par: `rabbitmq` (Deployment)

## üìö Pr√©requis

### Outils Requis

```bash
# Installation automatique de tous les outils
./Scripts/install-tools.sh

# V√©rification des installations
vagrant --version      # >= 2.3.0
VBoxManage --version  # >= 7.0
kubectl version --client  # >= 1.28.0
docker --version      # >= 24.0.0
```

### Compte Docker Hub (OBLIGATOIRE)

```bash
# Se connecter √† Docker Hub
docker login

# D√©finir votre username (ou utiliser le mien pour les tests)
export DOCKER_HUB_USERNAME="nocrarii"
```

## üöÄ Installation et Configuration

### 1Ô∏è‚É£ Construction et Push des Images Docker

```bash
# Optionnel: d√©finir votre compte Docker Hub
export DOCKER_HUB_USERNAME="nocrarii"   # ou votre username
docker login

# Build des images avec un tag (par d√©faut vYYYYMMDDHHMM)
./orchestrator.sh build                 # ex: tag auto
./orchestrator.sh build v1              # ex: tag explicite

# Build + push vers Docker Hub
./orchestrator.sh build v1 --push

# V√©rifier les images locales
docker images | grep ${DOCKER_HUB_USERNAME:-nocrarii}
```

Le build cr√©e et tague les images `api-gateway`, `inventory-app` et `billing-app`, puis met automatiquement √† jour les manifests Kubernetes pour pointer vers le nouveau tag.

### 2Ô∏è‚É£ Cr√©ation du Cluster K3s

```bash
# Cr√©er le cluster, configurer kubectl et d√©ployer les applications
./orchestrator.sh create

# Le script va :
# 1. Cr√©er 2 VMs via Vagrant
# 2. Installer K3s (master + agent)
# 3. Configurer kubectl
# 4. D√©ployer tous les manifests
# 5. Attendre que tout soit ready

# Sortie attendue : "cluster created"
```

### 3Ô∏è‚É£ V√©rification du Cluster

```bash
# V√©rifier les n≈ìuds (OBLIGATOIRE pour l'audit)
kubectl get nodes -A
# Attendu:
# NAME         STATUS   ROLES    AGE    VERSION
# k3s-master   Ready    <none>   XdXh   v1.28.3+k3s1
# k3s-agent    Ready    <none>   XdXh   v1.28.3+k3s1
```

## üéÆ Script Orchestrator (OBLIGATOIRE)

```bash
# Commandes principales pour l'audit
./orchestrator.sh create   # Cr√©e le cluster ET d√©ploie tout
./orchestrator.sh destroy  # D√©truit compl√®tement le cluster

# Alias pour compatibilit√© audit (mapp√©s dans le script)
./orchestrator.sh start    # ‚Üí √©quivalent √† create
./orchestrator.sh stop     # ‚Üí √©quivalent √† destroy

# Commandes suppl√©mentaires utiles
./orchestrator.sh status   # √âtat complet du cluster
./orchestrator.sh deploy   # Red√©ploiement des manifests
./orchestrator.sh build    # Build des images (+ option --push)
./orchestrator.sh logs <service>  # Voir les logs
./orchestrator.sh health   # Health check rapide
```

## üìù Explication de Chaque Manifest K8s

### secrets/db-secrets.yaml
- **R√¥le** : Stocke les credentials PostgreSQL encod√©s en base64
- **Contenu** : postgres-user, postgres-password, billing-user, inventory-user
- **Utilis√© par** : inventory-db, billing-db, inventory-app, billing-app

### secrets/rabbitmq-secrets.yaml
- **R√¥le** : Contient les identifiants RabbitMQ
- **Contenu** : rabbitmq-user, rabbitmq-password, erlang-cookie
- **Utilis√© par** : rabbitmq, billing-app

### configmaps/app-config.yaml
- **R√¥le** : Configuration centralis√©e des URLs et ports
- **Contenu** : INVENTORY_DB_HOST, BILLING_DB_HOST, RABBITMQ_HOST, ports
- **Utilis√© par** : Toutes les applications

### databases/inventory-db.yaml
- **Type** : StatefulSet (identit√© stable, stockage persistant)
- **Service** : Headless (pas de load balancing, connexion directe)
- **Volume** : PVC de 5Gi pour persistance
- **Port** : 5432

### databases/billing-db.yaml
- **Type** : StatefulSet (idem inventory-db)
- **Particularit√©** : Base "billing" avec table "orders"
- **Volume** : PVC de 5Gi s√©par√©

### apps/api-gateway.yaml
- **Type** : Deployment (stateless, scalable)
- **Service** : NodePort 30000 (accessible de l'ext√©rieur)
- **Env vars** : URLs des services backend
- **Resources** : 100m-200m CPU, 128Mi-256Mi RAM

### apps/inventory-app.yaml
- **Type** : Deployment (stateless)
- **Service** : ClusterIP (interne uniquement)
- **Connection** : PostgreSQL via secrets
- **HPA** : Autoscaling 1-3 replicas √† 60% CPU

### apps/billing-app.yaml
- **Type** : StatefulSet (ordre de traitement garanti)
- **Service** : Headless (pas de load balancing)
- **Particularit√©** : Consumer RabbitMQ ordonn√©
- **Raison** : Traitement s√©quentiel des messages

### messaging/rabbitmq.yaml
- **Type** : Deployment
- **Ports** : 5672 (AMQP), 15672 (Management UI)
- **Image** : rabbitmq:3.11-management-alpine

### Acc√®s √† l'UI RabbitMQ
- Par d√©faut, le Service est en `ClusterIP` (interne). Pour ouvrir l'UI de management:
  - Port‚Äëforward √©ph√©m√®re: `kubectl -n microservices port-forward svc/rabbitmq 15672:15672`
  - Navigateur: `http://localhost:15672`
  - Identifiants depuis le Secret: `admin / rabbitmq123` (ou lire le secret `rabbitmq-secrets`)
  - Option NodePort (debug r√©seau):
    - `kubectl -n microservices patch svc rabbitmq -p '{"spec":{"type":"NodePort","ports":[{"name":"amqp","port":5672,"targetPort":5672,"nodePort":30672},{"name":"management","port":15672,"targetPort":15672,"nodePort":31672}]}}'`
    - Acc√®s: `http://<NODE_IP>:31672`

### autoscaling/*.yaml
- **Type** : HorizontalPodAutoscaler
- **Cibles** : api-gateway et inventory-app
- **M√©triques** : CPU 60%, scale 1-3 replicas

## üîê Gestion des Secrets Kubernetes

```bash
# V√©rifier la pr√©sence des secrets (OBLIGATOIRE pour l'audit)
kubectl get secrets -n microservices
# Attendu : db-secrets, rabbitmq-secrets

# Encodage Base64 pour les secrets
echo -n "postgres" | base64        # ‚Üí cG9zdGdyZXM=
echo -n "postgres123" | base64     # ‚Üí cG9zdGdyZXMxMjM=

# Structure d'un secret
data:
  postgres-user: cG9zdGdyZXM=
  postgres-password: cG9zdGdyZXMxMjM=

# Afficher les identifiants RabbitMQ (d√©cod√©s)
kubectl get secret rabbitmq-secrets -n microservices -o jsonpath='{.data.rabbitmq-user}' | base64 -d; echo
kubectl get secret rabbitmq-secrets -n microservices -o jsonpath='{.data.rabbitmq-password}' | base64 -d; echo
```

## üèÉ Configuration des D√©ploiements

### Deployments avec Autoscaling (HPA)

| Service | Type | Min | Max | CPU Trigger | Justification |
|---------|------|-----|-----|-------------|---------------|
| **api-gateway** | Deployment | 1 | 3 | 60% | Stateless, point d'entr√©e scalable |
| **inventory-app** | Deployment | 1 | 3 | 60% | Stateless, lectures parall√®les |

### StatefulSets (Applications avec √âtat)

| Service | Type | Replicas | Justification |
|---------|------|----------|---------------|
| **billing-app** | StatefulSet | 1 | Traitement ordonn√© des messages RabbitMQ |
| **inventory-db** | StatefulSet | 1 | Persistance + identit√© stable pour connexions |
| **billing-db** | StatefulSet | 1 | Persistance + identit√© stable pour connexions |

### ‚ùì Pourquoi StatefulSet pour les Bases de Donn√©es ?

**On ne met JAMAIS les bases de donn√©es en Deployment car :**
1. **Donn√©es persistantes** : Les volumes doivent survivre aux red√©marrages
2. **Identit√© stable** : billing-db-0 reste toujours billing-db-0
3. **√âcriture unique** : Un seul pod √©crit dans un volume (√©vite corruption)
4. **Ordre de d√©marrage** : Important pour r√©plication master/slave
5. **DNS pr√©dictible** : `billing-db-0.billing-db.microservices.svc.cluster.local`

## üß™ Tests de l'Application (Audit Requirements)

### 1. Test de l'API d'Inventaire

```bash
# Obtenir l'IP du n≈ìud
NODE_IP=$(kubectl get nodes -o wide | grep agent | awk '{print $6}')
# Si pas d'agent, utiliser master
[[ -z "$NODE_IP" ]] && NODE_IP=$(kubectl get nodes -o wide | grep master | awk '{print $6}')

# POST - Cr√©er un film (TEST OBLIGATOIRE)
curl -X POST http://${NODE_IP}:30000/api/movies/ \
  -H "Content-Type: application/json" \
  -d '{
    "title": "A new movie",
    "description": "Very short description"
  }'
# R√©ponse attendue : 200 OK

# GET - R√©cup√©rer les films (TEST OBLIGATOIRE)
curl http://${NODE_IP}:30000/api/movies/
# R√©ponse attendue : 200 OK avec JSON contenant le film cr√©√©
```

### 2. Test de l'API de Facturation

```bash
# POST - Cr√©er une commande (TEST OBLIGATOIRE)
curl -X POST http://${NODE_IP}:30000/api/billing/ \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "20",
    "number_of_items": "99",
    "total_amount": "250"
  }'
# R√©ponse attendue : 200 OK
```

### 3. Test de R√©silience avec RabbitMQ (TEST OBLIGATOIRE)

```bash
# 1. Arr√™ter billing-app
kubectl scale statefulset billing-app -n microservices --replicas=0

# 2. V√©rifier l'arr√™t
kubectl get pods -n microservices | grep billing-app
# Attendu : Aucun pod

# 3. Envoyer une commande (sera mise en queue)
curl -X POST http://${NODE_IP}:30000/api/billing/ \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "22",
    "number_of_items": "10",
    "total_amount": "50"
  }'
# R√©ponse attendue : 200 OK (message en queue)

# 4. Red√©marrer billing-app
kubectl scale statefulset billing-app -n microservices --replicas=1

# 5. Attendre le traitement
sleep 30
```

### 4. V√©rification Base de Donn√©es (TEST OBLIGATOIRE)

```bash
# Acc√®s √† la base billing (ATTENTION: billing-db-0, pas billing-database-0)
kubectl exec -it billing-db-0 -n microservices -- sh

# Dans le conteneur
su - postgres  # ou sudo -i -u postgres
psql

# Dans psql :
\l                    # Liste les bases, v√©rifier "billing" existe
\c billing            # Se connecter √† la base billing
TABLE orders;         # Afficher la table orders

# V√©rifier :
# - user_id=20 DOIT √™tre pr√©sent
# - user_id=22 DOIT √™tre pr√©sent (apr√®s red√©marrage billing-app)

\q
exit
exit
```

## üìä Concepts Th√©oriques (Questions d'Audit)

### Container Orchestration
**D√©finition** : Gestion automatis√©e du d√©ploiement, de la mise √† l'√©chelle et de l'exploitation des conteneurs.

**Avantages** :
- ‚úÖ D√©ploiement automatis√© et reproductible
- ‚úÖ Mise √† l'√©chelle automatique selon la charge
- ‚úÖ Auto-gu√©rison (red√©marrage automatique)
- ‚úÖ √âquilibrage de charge int√©gr√©
- ‚úÖ Gestion centralis√©e de la configuration

### Kubernetes
**R√¥le principal** : Plateforme open-source d'orchestration de conteneurs qui automatise le d√©ploiement, la mise √† l'√©chelle et la gestion des applications conteneuris√©es.

### K3s
**R√¥le principal** : Distribution Kubernetes l√©g√®re (<100MB) optimis√©e pour l'edge computing, l'IoT et les environnements de d√©veloppement. Un seul binaire, installation simplifi√©e.

### Infrastructure as Code (IaC)
**D√©finition** : Gestion de l'infrastructure via des fichiers de configuration versionn√©s.

**Avantages** :
- Version control de l'infrastructure
- Reproductibilit√© garantie
- Documentation vivante
- Automatisation CI/CD
- Revue de code possible

### K8s Manifest
**D√©finition** : Fichier YAML d√©clarant l'√©tat souhait√© d'une ressource Kubernetes. Contient apiVersion, kind, metadata et spec.

### StatefulSet vs Deployment

| Aspect | StatefulSet | Deployment |
|--------|------------|------------|
| **Utilisation** | Applications avec √©tat (DB, queues) | Applications sans √©tat (API, web) |
| **Identit√© des pods** | Stable (pod-0, pod-1) | Al√©atoire (pod-xyz123) |
| **Stockage** | PersistentVolume individuel | Pas de stockage ou partag√© |
| **Ordre de d√©marrage** | S√©quentiel (0, puis 1, puis 2) | Parall√®le (tous en m√™me temps) |
| **Mise √† jour** | Un par un (rolling) | Rolling update configurable |
| **DNS** | Nom pr√©dictible | Nom al√©atoire |

### Scaling
**D√©finition** : Ajustement des ressources selon la charge.
- **Horizontal (HPA)** : Ajouter/supprimer des pods
- **Vertical (VPA)** : Augmenter CPU/RAM par pod

### Load Balancer
**R√¥le** : Distribution du trafic entre plusieurs instances pour haute disponibilit√© et performance optimale.

## üîç Composants Kubernetes (< 15 minutes)

### Control Plane (Master)
- **kube-apiserver** : API REST, point d'entr√©e unique
- **etcd** : Base cl√©-valeur distribu√©e (√©tat du cluster)
- **kube-scheduler** : Assigne pods aux n≈ìuds selon ressources
- **kube-controller-manager** : Boucles de contr√¥le (Deployment, ReplicaSet)
- **cloud-controller-manager** : Int√©gration cloud (non utilis√© en K3s)

### Node Components (Workers)
- **kubelet** : Agent sur chaque n≈ìud, g√®re les pods
- **kube-proxy** : Rules iptables pour le r√©seau
- **Container Runtime** : Ex√©cute conteneurs (containerd dans K3s)

### Add-ons
- **CoreDNS** : R√©solution DNS interne
- **Metrics Server** : M√©triques CPU/RAM pour HPA
- **Dashboard** : UI web (optionnel)

## ‚úÖ V√©rifications pour l'Audit

```bash
# 1. kubectl configur√©
kubectl version --client
export KUBECONFIG=$(pwd)/k3s.yaml

# 2. Cluster cr√©√© par Vagrantfile
vagrant status
# Attendu : master et agent "running"

# 3. Deux n≈ìuds connect√©s
kubectl get nodes -A
# Attendu : k3s-master Ready, k3s-agent Ready

# 4. Namespace et secrets
kubectl get ns microservices
kubectl get secrets -n microservices
# Attendu : db-secrets, rabbitmq-secrets

# 5. D√©ploiements corrects
kubectl get deploy,sts -n microservices
# Deployments : api-gateway, inventory-app, rabbitmq
# StatefulSets : billing-app, billing-db, inventory-db

# 6. HPA configur√©
kubectl get hpa -n microservices
# Attendu : api-gateway-hpa, inventory-app-hpa (60% CPU)

# 7. Tous les pods Running
kubectl get pods -n microservices
# Tous doivent √™tre Running ou Completed

# 8. Images Docker Hub correctes
kubectl get pods -n microservices -o jsonpath="{..image}" | tr -s '[[:space:]]' '\n' | sort | uniq | grep nocrarii
# Doit montrer : nocrarii/api-gateway, nocrarii/inventory-app, nocrarii/billing-app
```

## üõ†Ô∏è D√©pannage

### Probl√®mes Courants

**Pod en CrashLoopBackOff**
```bash
kubectl describe pod <pod-name> -n microservices
kubectl logs <pod-name> -n microservices --previous
```

**Base de donn√©es inaccessible**
```bash
# V√©rifier le secret
kubectl get secret db-secrets -n microservices -o yaml

# Tester la connexion
kubectl exec -it inventory-app-xxx -n microservices -- \
  psql -h inventory-db -U postgres -d inventory
```

**Agent non connect√©**
```bash
vagrant ssh agent
sudo systemctl status k3s-agent
sudo journalctl -u k3s-agent -f
```

## üìà Observabilit√© (Prometheus/Grafana)

- Endpoints `/metrics` expos√©s par: `api-gateway` et `inventory-app` (Prometheus client Python).
- ServiceMonitors: `Manifests/monitoring/servicemonitors.yaml` (scrape chemin `/metrics` sur port nomm√© `http`).
- Installer Prometheus Operator + stack kube-prometheus:
  ```bash
  bash Scripts/install-prometheus-operator.sh
  kubectl get crd | grep monitoring.coreos.com
  kubectl -n monitoring get pods,svc
  ```
- Dashboard Grafana pr√™t √† l‚Äôemploi: `Manifests/monitoring/grafana-dashboard.yaml` (label `grafana_dashboard: "1"`).

## üîß D√©tails du Workflow de Build

- Pr√©requis: `docker login` et `export DOCKER_HUB_USERNAME="<vous>"` (d√©faut: `nocrarii`).
- Construire et tagger: `./orchestrator.sh build [TAG]` (tag auto par d√©faut).
- Pousser: `./orchestrator.sh build <TAG> --push`.
- Construit: `api-gateway`, `inventory-app`, `billing-app`, `postgres-db`, `rabbitmq`.
- Effet: met √† jour `Manifests/apps/*.yaml`, `Manifests/databases/*-db.yaml`, `Manifests/messaging/rabbitmq.yaml` pour pointer sur `<TAG>`; ensuite `./orchestrator.sh deploy` pour appliquer.
- Script autonome √©quivalent: `./Scripts/build-images.sh <TAG> [--push]`.

## üéÅ Bonus Impl√©ment√©s

- ‚úÖ Health checks et readiness probes sur tous les services
- ‚úÖ Resource limits et requests configur√©s
- ‚úÖ Scripts utilitaires complets (test-api.sh, healthcheck.sh)
- ‚úÖ Gestion des erreurs et retry logic dans les apps
- ‚úÖ Documentation exhaustive
- ‚úÖ Architecture diagram d√©taill√©

### Suggestions de Bonus Suppl√©mentaires
- üìä Dashboard Kubernetes
- üìù Stack de logs (ELK/Loki)
- üîç Monitoring (Prometheus/Grafana)
- üåê Ingress Controller

## üìù Notes Importantes pour l'Audit

1. ‚úÖ **README.md contient TOUTES les informations** requises
2. ‚úÖ **Images Docker sur Docker Hub** compte nocrarii
3. ‚úÖ **Script orchestrator.sh** avec create/start/stop/destroy
4. ‚úÖ **Architecture respect√©e** exactement comme demand√©
5. ‚úÖ **Tous les secrets** dans manifests s√©par√©s
6. ‚úÖ **Scaling configur√©** : 60% CPU, 1-3 replicas
7. ‚úÖ **2 VMs K3s** : master et agent via Vagrant
8. ‚úÖ **Explication des manifests** fournie
9. ‚úÖ **Tests de r√©silience** document√©s
10. ‚úÖ **Composants K8s** expliqu√©s

## ü§ù Support et Ressources

- Documentation Kubernetes : https://kubernetes.io/docs
- Documentation K3s : https://docs.k3s.io
- Training Kubernetes : https://kubernetes.io/training/
- Docker Hub du projet : https://hub.docker.com/u/nocrarii

---

**üìå Projet r√©alis√© dans le cadre du module ORCHESTRATOR - Infrastructure as Code avec Kubernetes**

**üë®‚Äçüíª Auteur : Projet √©tudiant avec images Docker Hub nocrarii**

**‚öñÔ∏è License : Projet √©ducatif - Usage libre pour apprentissage**
